# Physical Product Platform - Analytics Engineering Project

A production-ready analytics engineering project simulating a comprehensive physical product platform with end-to-end data pipeline, transformations, and analytics capabilities.

## ğŸ¯ Project Overview

This project demonstrates a complete analytics engineering solution for a physical product platform, covering the entire data lifecycle from raw data generation to analytics-ready data marts. It includes data generators, ingestion pipelines, data transformations using dbt, orchestration with Airflow, and analytics-ready outputs for BI tools like Tableau.

## ğŸ“Š Business Domains

The project covers 8 key business domains:

1. **Products** - Product catalog, SKUs, categories, pricing
2. **Recipes** - Bill of materials, ingredients, manufacturing recipes
3. **Customers** - Customer demographics, segments, accounts
4. **Orders** - Sales orders, order lines, order status
5. **Shipments** - Delivery tracking, logistics, fulfillment
6. **Returns** - Return requests, reasons, refund processing
7. **Waste** - Manufacturing waste, scrap tracking, sustainability metrics
8. **Quality** - Quality control checks, defects, compliance

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data Generators â”‚ (Python CSV Generators)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Raw Data Lake  â”‚ (CSV Files)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Ingestion    â”‚ (Python Scripts + Airflow)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Warehouse â”‚ (Databricks/Snowflake/BigQuery)
â”‚   Raw Layer     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  dbt Transform  â”‚ (Staging + Marts)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Analytics Layer â”‚ (Tableau-Ready Marts)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ data_generators/          # Python scripts to generate sample data
â”‚   â”œâ”€â”€ generate_products.py
â”‚   â”œâ”€â”€ generate_recipes.py
â”‚   â”œâ”€â”€ generate_customers.py
â”‚   â”œâ”€â”€ generate_orders.py
â”‚   â”œâ”€â”€ generate_shipments.py
â”‚   â”œâ”€â”€ generate_returns.py
â”‚   â”œâ”€â”€ generate_waste.py
â”‚   â”œâ”€â”€ generate_quality.py
â”‚   â””â”€â”€ generate_all.py
â”œâ”€â”€ ingestion/               # Data ingestion scripts
â”‚   â”œâ”€â”€ ingest_to_databricks.py
â”‚   â”œâ”€â”€ ingest_to_snowflake.py
â”‚   â”œâ”€â”€ ingest_to_bigquery.py
â”‚   â””â”€â”€ config.yaml
â”œâ”€â”€ schemas/                 # Database schema definitions
â”‚   â”œâ”€â”€ databricks/
â”‚   â”œâ”€â”€ snowflake/
â”‚   â””â”€â”€ bigquery/
â”œâ”€â”€ dbt_project/            # dbt transformation project
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/       # Staging models (1:1 with sources)
â”‚   â”‚   â””â”€â”€ marts/         # Analytics marts (dimensional model)
â”‚   â”œâ”€â”€ tests/             # Data quality tests
â”‚   â”œâ”€â”€ macros/            # Reusable SQL macros
â”‚   â””â”€â”€ dbt_project.yml
â”œâ”€â”€ airflow/                # Airflow orchestration
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â”œâ”€â”€ dag_ingestion.py
â”‚   â”‚   â”œâ”€â”€ dag_dbt_transform.py
â”‚   â”‚   â””â”€â”€ dag_quality_checks.py
â”‚   â””â”€â”€ config/
â”œâ”€â”€ docs/                   # Documentation
â”‚   â”œâ”€â”€ setup.md
â”‚   â”œâ”€â”€ architecture.md
â”‚   â””â”€â”€ metrics.md
â””â”€â”€ sample_data/           # Generated sample data (gitignored)
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- pip or conda
- Access to one of: Databricks, Snowflake, or BigQuery
- Apache Airflow (optional, for orchestration)
- dbt-core (for transformations)

### Installation

1. Clone the repository:
```bash
git clone https://github.com/Akshay0649/Data-Engineering-2.git
cd Data-Engineering-2
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Generate sample data:
```bash
python data_generators/generate_all.py
```

4. Configure your data warehouse connection in `ingestion/config.yaml`

5. Run ingestion:
```bash
python ingestion/ingest_to_[platform].py
```

6. Run dbt transformations:
```bash
cd dbt_project
dbt deps
dbt run
dbt test
```

## ğŸ“ˆ Key Metrics & KPIs

### Product Operations
- **Product Performance**: Sales by SKU, category, region
- **Inventory Turnover**: Stock velocity, reorder points
- **Recipe Efficiency**: Ingredient utilization, yield rates

### Customer Analytics
- **Customer Lifetime Value (CLV)**: Revenue per customer over time
- **Customer Segmentation**: RFM analysis, cohort analysis
- **Retention Metrics**: Repeat purchase rate, churn rate

### Order Fulfillment
- **Order Metrics**: Order volume, average order value, order frequency
- **Fulfillment Rate**: On-time delivery, shipping time
- **Return Rate**: Returns by category, return reasons

### Quality & Waste
- **Quality Metrics**: Defect rate, quality score, compliance rate
- **Waste Metrics**: Waste percentage, scrap cost, sustainability score
- **Operational Efficiency**: Overall Equipment Effectiveness (OEE)

## ğŸ§ª Testing Strategy

The project includes multiple layers of testing:

1. **Schema Tests** (dbt): Uniqueness, not null, relationships, accepted values
2. **Data Quality Tests** (dbt): Custom business logic validation
3. **Ingestion Tests**: Data completeness, format validation
4. **Airflow Tests**: DAG integrity, task dependencies

## ğŸ“š Documentation

- [Setup Guide](docs/setup.md) - Detailed installation and configuration
- [Architecture](docs/architecture.md) - System design and data flow
- [Metrics Guide](docs/metrics.md) - Available metrics and calculations

## ğŸ”§ Technologies Used

- **Data Generation**: Python, Faker, pandas
- **Data Warehouses**: Databricks, Snowflake, BigQuery
- **Transformation**: dbt (data build tool)
- **Orchestration**: Apache Airflow
- **BI/Visualization**: Tableau (compatible outputs)
- **Version Control**: Git

## ğŸ¤ Contributing

This is a demonstration project. Feel free to fork and adapt for your own use cases.

## ğŸ“ License

MIT License

## ğŸ‘¤ Author

Akshay0649

---

**Note**: This is a simulated environment for learning and demonstration purposes. Adapt configurations for production use. 
